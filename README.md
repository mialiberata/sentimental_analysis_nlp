# ğŸ” AnÃ¡lise de Sentimento com BERT

Oi, Mia aqui! Ö´Ö¶Ö¸ğ“‚ƒ à£ªË– Ö´Ö¶Ö¸ğŸ‡à¼‹à¼˜à¿
Se tem uma coisa que me fascina, Ã© como palavras carregam camadas de significado. â¸œ(ï½¡Ëƒ áµ• Ë‚ )â¸â™¡
Algumas marcas despertam paixÃ£o, outras irritaÃ§Ã£o, e Ã s vezes a gente sÃ³ segue a vida sem se importar muito, mas como isso se traduz na linguagem? 
Como verbos e adjetivos revelam nossas percepÃ§Ãµes sobre empresas gigantes como Google, Tesla, Coca-Cola e Meta?

Este projeto Ã© exatamente sobre isso. Peguei um modelo **BERT**, treinei com um dataset de frases sobre essas marcas e criei uma API para analisar **se um texto expressa sentimento positivo, negativo ou neutro**. Bora ver como funciona? ğŸ‘€

## ğŸ¯ **O que eu queria com isso?** 

Mais do que um classificador de sentimentos qualquer, eu quero entender **o que gera cada emoÃ§Ã£o**. NÃ£o basta saber que alguÃ©m â€œamaâ€ ou â€œodeiaâ€ uma marca, Ã© preciso entender **por quÃª**. E aÃ­ entra a importÃ¢ncia dos **verbos e adjetivos** usados. A estrutura da frase conta muito!

## ğŸ¢ **Por que essas marcas?**

A escolha nÃ£o foi aleatÃ³ria. Essas empresas dominam nossas interaÃ§Ãµes diÃ¡rias e, justamente por isso, despertam todo tipo de sentimento:

- **Coca-Cola** ğŸ¥¤ â€” Associada a nostalgia, prazer e questÃµes de saÃºde.
- **Meta (Facebook, Instagram, WhatsApp)** ğŸ“± â€” InovaÃ§Ã£o digital vs. privacidade e anÃºncios excessivos.
- **Tesla** ğŸš—âš¡ â€” Futurismo, status e promessas vs. acessibilidade e suporte ao consumidor.
- **Google** ğŸŒğŸ” â€” Ferramenta essencial vs. invasÃ£o de dados e monopÃ³lio digital.

NÃ£o estou interessada sÃ³ na polaridade (*positivo/negativo*), mas nos **padrÃµes linguÃ­sticos que sustentam essas percepÃ§Ãµes**.
Espero conseguir aprimorar esse cÃ³digo no futuro para chegar no resultado que imagino.

## ğŸ› ï¸ **O que o cÃ³digo faz?**

### ğŸ“Š CriaÃ§Ã£o do dataset
- Selecionei frases sobre marcas.
- Rotulei cada uma como **positiva, negativa ou neutra**.
- Os verbos e adjetivos foram analisados para entender o tom de cada sentenÃ§a.

### ğŸ”¤ TokenizaÃ§Ã£o com BERT
- O `BertTokenizer` converte os textos para um formato numÃ©rico.
- O modelo `bert-base-uncased` gera embeddings contextuais que ajudam na classificaÃ§Ã£o.

### ğŸ‹ï¸ Treinamento do modelo
- Separei os dados em **80% treino e 20% teste**.
- O modelo aprendeu a associar padrÃµes linguÃ­sticos a sentimentos.
- Usei `CrossEntropyLoss` e `AdamW` para otimizaÃ§Ã£o.

### (à¸‡ Í à²¥_à²¥)à¸‡ CriaÃ§Ã£o da API
- Recebe textos via requisiÃ§Ã£o `POST`.
- O modelo processa e devolve a classificaÃ§Ã£o (`positivo`, `neutro` ou `negativo`).
- Erros sÃ£o tratados de forma clara.

## ğŸ’« **Como rodar isso?**

### 1ï¸âƒ£ Executar o cÃ³digo
```bash
python nome_do_arquivo.py
```

### 2ï¸âƒ£ Testar a API
```bash
curl -X POST http://127.0.0.1:5000/predict \
     -H "Content-Type: application/json" \
     -d '{"text": "A Tesla tem um design incrÃ­vel!"}'
```

### ğŸ”š SaÃ­da esperada:
```json
{"sentimento": "positivo"}
```

## â­ **Por que isso Ã© Ãºtil?**
- Empresas podem entender **o impacto emocional de suas estratÃ©gias**.
- O comportamento linguÃ­stico do consumidor pode indicar padrÃµes de aceitaÃ§Ã£o ou rejeiÃ§Ã£o.
- Ferramenta Ãºtil para **monitoramento de redes sociais e feedbacks**.

## ğŸ“Œ **O que vem depois?**
âœ… Expandir o dataset com exemplos reais.  
âœ… Ajustar hiperparÃ¢metros para refinar o modelo.  
âœ… Explorar emoÃ§Ãµes mais especÃ­ficas alÃ©m de positivo/negativo.  

âœ‰ï¸ **DÃºvidas, surtos ou sugestÃµes? Deixe seu recado apÃ³s o beep.** BEEEEEEP! 
